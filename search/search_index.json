{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"HMAX documentation Welcome to the HMAX documentation (version Renoult et al. 2019). For instructions about how to install the MATLAB package, go here . If you have already downloaded the package, go here to start using it. What is HMAX? HMAX is a computational model of information processing in the ventral pathway of the visal cortex, which is involved in colour and shape perception. The model was proposed originally by Riesenhuber Poggio (1999). What is new in this version? This version of HMAX offers high flexibility in parameter setting and thus can be easily tuned to model the perception of colour patterns in a wide array of Vertebrate species. Furthermore, it is possible to learn filters (i.e. neuronal selectivities) using a sparseness constraint, or to force sparseness when coding an image with a given set of filters. As in the version proposed by Zhang et al. (2012), it can process greyscale or colour images; however, it is up to 25% faster. Renoult et al. (2019) provides a complete description of the model. References Mutch, J., Lowe, D. G. (2006). Multiclass object recognition with sparse, localized features. In Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on (Vol. 1, pp. 11-18). IEEE. Renoult, J.P., Guyl, B., Mendelson, T.C., et al. (2019). Modelling the Perception of Colour Patterns in Vertebrates with HMAX. preprint here. Riesenhuber, M., Poggio, T. (1999). Hierarchical models of object recognition in cortex. Nature neuroscience, 2(11), 1019. Serre, T., Wolf, L., Bileschi, S., Riesenhuber, M., Poggio, T. (2007). Robust object recognition with cortex-like mechanisms. IEEE Transactions on Pattern Analysis Machine Intelligence, (3), 411-426. Zhang, J., Barhomi, Y., Serre, T. (2012, October). A new biologically inspired color image descriptor. In European Conference on Computer Vision (pp. 312-324). Springer, Berlin, Heidelberg. Links Riesenhuber (original HMAX) http://maxlab.neuro.georgetown.edu/hmax Serre (codes for HMAX and colour HMAX) https://github.com/serre-lab/color_hmax Mutch (yet another implement of HMAX) http://cbcl.mit.edu/jmutch/cns About us You can find more on our EEVCOM webpage.","title":"Home"},{"location":"#hmax-documentation","text":"Welcome to the HMAX documentation (version Renoult et al. 2019). For instructions about how to install the MATLAB package, go here . If you have already downloaded the package, go here to start using it.","title":"HMAX documentation"},{"location":"#what-is-hmax","text":"HMAX is a computational model of information processing in the ventral pathway of the visal cortex, which is involved in colour and shape perception. The model was proposed originally by Riesenhuber Poggio (1999).","title":"What is HMAX?"},{"location":"#what-is-new-in-this-version","text":"This version of HMAX offers high flexibility in parameter setting and thus can be easily tuned to model the perception of colour patterns in a wide array of Vertebrate species. Furthermore, it is possible to learn filters (i.e. neuronal selectivities) using a sparseness constraint, or to force sparseness when coding an image with a given set of filters. As in the version proposed by Zhang et al. (2012), it can process greyscale or colour images; however, it is up to 25% faster. Renoult et al. (2019) provides a complete description of the model.","title":"What is new in this version?"},{"location":"#references","text":"Mutch, J., Lowe, D. G. (2006). Multiclass object recognition with sparse, localized features. In Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on (Vol. 1, pp. 11-18). IEEE. Renoult, J.P., Guyl, B., Mendelson, T.C., et al. (2019). Modelling the Perception of Colour Patterns in Vertebrates with HMAX. preprint here. Riesenhuber, M., Poggio, T. (1999). Hierarchical models of object recognition in cortex. Nature neuroscience, 2(11), 1019. Serre, T., Wolf, L., Bileschi, S., Riesenhuber, M., Poggio, T. (2007). Robust object recognition with cortex-like mechanisms. IEEE Transactions on Pattern Analysis Machine Intelligence, (3), 411-426. Zhang, J., Barhomi, Y., Serre, T. (2012, October). A new biologically inspired color image descriptor. In European Conference on Computer Vision (pp. 312-324). Springer, Berlin, Heidelberg.","title":"References"},{"location":"#links","text":"","title":"Links"},{"location":"#riesenhuber-original-hmax","text":"http://maxlab.neuro.georgetown.edu/hmax","title":"Riesenhuber (original HMAX)"},{"location":"#serre-codes-for-hmax-and-colour-hmax","text":"https://github.com/serre-lab/color_hmax","title":"Serre (codes for HMAX and colour HMAX)"},{"location":"#mutch-yet-another-implement-of-hmax","text":"http://cbcl.mit.edu/jmutch/cns","title":"Mutch (yet another implement of HMAX)"},{"location":"#about-us","text":"You can find more on our EEVCOM webpage.","title":"About us"},{"location":"get-started/","text":"Get started This section will show you how to run the code to classify images. Prepare your dataset First, you must prepare your dataset. HMAX requires a learning step during which filter selectivities are learned. You thus need to have a learning dataset, which can be different (or not) from the encoding dataset. The encoding dataset includes images that you want to encode using HMAX with learned filters. Quick start This will show you how to run HMAX with the default configuration. Computations are not paralyzed or putted on the GPU. You should do this on a small dataset first as it can take some time. 1 . Open the project with Matlab. 2 . Then, you need to train the model with the dataset you have prepared hmax('../dataset/train/', 'Train', true); 3 . Run it on your test dataset hmax('../dataset/test/'); This will read recursively the ../dataset/test/ folder architecture and create a similar one in the ./result folder. Each images will give a Matlab binary file containing the HMAX encoding. 4 . If your folders are named corresponding to the class name of the images, then you can run the following command: T = classifier.loadC2s('./results/'); Where T is a table containing HMAX encodings with corresponding labels. Machine Learning Once you've done the step 4. , you can use the data in a Machine Learning tool. The recommendation is to split the data ( T ) in two, one with 80% of the observations for training and the other with the rest of the 20% for validation. [Ttrain Ttest] = classifier.splitdata(T, 0.8); Then, you can use the Classification Learner toolbox to create a model. For our tests, we used a Linear SVM without PCA. Finally, we can test our model averagePrecision = classifier.runtest(trainedModel, Ttest) Go further Now that you know how to run HMAX, we will see how to run the code with GPU, parallel computing, with your own parameters, etc ...","title":"Get started"},{"location":"get-started/#get-started","text":"This section will show you how to run the code to classify images.","title":"Get started"},{"location":"get-started/#prepare-your-dataset","text":"First, you must prepare your dataset. HMAX requires a learning step during which filter selectivities are learned. You thus need to have a learning dataset, which can be different (or not) from the encoding dataset. The encoding dataset includes images that you want to encode using HMAX with learned filters.","title":"Prepare your dataset"},{"location":"get-started/#quick-start","text":"This will show you how to run HMAX with the default configuration. Computations are not paralyzed or putted on the GPU. You should do this on a small dataset first as it can take some time. 1 . Open the project with Matlab. 2 . Then, you need to train the model with the dataset you have prepared hmax('../dataset/train/', 'Train', true); 3 . Run it on your test dataset hmax('../dataset/test/'); This will read recursively the ../dataset/test/ folder architecture and create a similar one in the ./result folder. Each images will give a Matlab binary file containing the HMAX encoding. 4 . If your folders are named corresponding to the class name of the images, then you can run the following command: T = classifier.loadC2s('./results/'); Where T is a table containing HMAX encodings with corresponding labels.","title":"Quick start"},{"location":"get-started/#machine-learning","text":"Once you've done the step 4. , you can use the data in a Machine Learning tool. The recommendation is to split the data ( T ) in two, one with 80% of the observations for training and the other with the rest of the 20% for validation. [Ttrain Ttest] = classifier.splitdata(T, 0.8); Then, you can use the Classification Learner toolbox to create a model. For our tests, we used a Linear SVM without PCA. Finally, we can test our model averagePrecision = classifier.runtest(trainedModel, Ttest)","title":"Machine Learning"},{"location":"get-started/#go-further","text":"Now that you know how to run HMAX, we will see how to run the code with GPU, parallel computing, with your own parameters, etc ...","title":"Go further"},{"location":"indeep/","text":"In deep In this section, we will show how to use advanced parameter setting in HMAX. If you haven't read it yet, you should start with the Get started section. How to specify parameters There is two ways to set parameters in the program: Directly through the Matlab command From a configuration file The priority is given to: 1. Parameters set through the Matlab command 2. Parameters written in the configuration file 3. Parameters set internally That's why in the Get started section, we wrote: hmax('../dataset/train/', 'Train', true); The Train parameter is set to false internally and in the default configuration file. Setting the parameter to true will override the default value. Avalaible parameters Name Description Type expected Default value ConfigurationFile Custom configuration file String - JSON file \"./defaultParameters.json\" Output Custom output directory String - Directory \"./results\" GPU Use GPU for computation Boolean false Parallel Use parallel computing Boolean false Engine Specify an algorithm to use String \"sparseCodingColor\" ImageSize Resize image to this size in pixels Integer 140 GaborNbOrientations Nb. of oritentions for Gabor filters Integer 4 GaborAspectRatio Spatial aspect ratio of Gabor filters Float 0.3 GaborEffectiveWidth Width of Gabor filters Float[] [2.8, 3.6, 4.5, ..., 18.2] GaborWavelength Wavelength of Gabor filters Float[] [3.5, 4.6, 5.6, ..., 22.8] GaborSizes Sizes of Gabor filters Integer[] [7, 9, 11, 13, ..., 39] FiltersSizes Sizes of S2 filters Integer[] [4, 8, 12, 16] MaxPoolingSizes Size of the max pooling Integer[] [8, 8, 10, 10, ..., 22] ColorNbChannels Nb. of color channels Integer 4 SparseCodingFilterSize Sizes of S2 filters (sparse HMAX) Integer 12 SparseCodingNbPatches Nb. of patches extracted (sparse HMAX) Integer 10000 SparseCodingBatchSize Nb. of patches in one batch during filter learning (sparse HMAX) Integer 1000 SparseCodingNbIterations Nb. of iterations during filter learning (sparse HMAX) Integer 2 SparseCodingPenalty Importance given to sparseness versus reconstruction error (sparse HMAX) Float 0.2 NbFilters Nb. of S2 fitlers (sparse HMAX) Integer 1000 Train Train the model Boolean false Engine Choose between: classic (HMAX with greyscale images), sparseCoding (HMAX with sparse coding), color (HMAX with colour images) or sparseColor (HMAX with sparse coding on colour images) ImageSize Input images are resized to have their smallest side equal to the defined value keeping aspect ration constant. Large images increase computation time. GaborEffectiveWidth Default values: [2.8, 3.6, 4.5, 5.4, 6.3, 7.3, 8.2, 9.2, 10.2, 11.3, 12.3, 13.4, 14.6, 15.8, 17.0, 18.2] GaborWavelength Default values: [3.5, 4.6, 5.6, 6.8, 7.9, 9.1, 10.3, 11.5, 12.7, 14.1, 15.4, 16.8, 18.2, 19.7, 21.2, 22.8] GaborFilterSizes Default values: [7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37] MaxPoolingSizes Default values: [8, 8, 10, 10, 12, 12, 14, 14, 16, 16, 18, 18, 20, 20, 22, 22]","title":"In deep"},{"location":"indeep/#in-deep","text":"In this section, we will show how to use advanced parameter setting in HMAX. If you haven't read it yet, you should start with the Get started section.","title":"In deep"},{"location":"indeep/#how-to-specify-parameters","text":"There is two ways to set parameters in the program: Directly through the Matlab command From a configuration file The priority is given to: 1. Parameters set through the Matlab command 2. Parameters written in the configuration file 3. Parameters set internally That's why in the Get started section, we wrote: hmax('../dataset/train/', 'Train', true); The Train parameter is set to false internally and in the default configuration file. Setting the parameter to true will override the default value.","title":"How to specify parameters"},{"location":"indeep/#avalaible-parameters","text":"Name Description Type expected Default value ConfigurationFile Custom configuration file String - JSON file \"./defaultParameters.json\" Output Custom output directory String - Directory \"./results\" GPU Use GPU for computation Boolean false Parallel Use parallel computing Boolean false Engine Specify an algorithm to use String \"sparseCodingColor\" ImageSize Resize image to this size in pixels Integer 140 GaborNbOrientations Nb. of oritentions for Gabor filters Integer 4 GaborAspectRatio Spatial aspect ratio of Gabor filters Float 0.3 GaborEffectiveWidth Width of Gabor filters Float[] [2.8, 3.6, 4.5, ..., 18.2] GaborWavelength Wavelength of Gabor filters Float[] [3.5, 4.6, 5.6, ..., 22.8] GaborSizes Sizes of Gabor filters Integer[] [7, 9, 11, 13, ..., 39] FiltersSizes Sizes of S2 filters Integer[] [4, 8, 12, 16] MaxPoolingSizes Size of the max pooling Integer[] [8, 8, 10, 10, ..., 22] ColorNbChannels Nb. of color channels Integer 4 SparseCodingFilterSize Sizes of S2 filters (sparse HMAX) Integer 12 SparseCodingNbPatches Nb. of patches extracted (sparse HMAX) Integer 10000 SparseCodingBatchSize Nb. of patches in one batch during filter learning (sparse HMAX) Integer 1000 SparseCodingNbIterations Nb. of iterations during filter learning (sparse HMAX) Integer 2 SparseCodingPenalty Importance given to sparseness versus reconstruction error (sparse HMAX) Float 0.2 NbFilters Nb. of S2 fitlers (sparse HMAX) Integer 1000 Train Train the model Boolean false","title":"Avalaible parameters"},{"location":"indeep/#engine","text":"Choose between: classic (HMAX with greyscale images), sparseCoding (HMAX with sparse coding), color (HMAX with colour images) or sparseColor (HMAX with sparse coding on colour images)","title":"Engine"},{"location":"indeep/#imagesize","text":"Input images are resized to have their smallest side equal to the defined value keeping aspect ration constant. Large images increase computation time.","title":"ImageSize"},{"location":"indeep/#gaboreffectivewidth","text":"Default values: [2.8, 3.6, 4.5, 5.4, 6.3, 7.3, 8.2, 9.2, 10.2, 11.3, 12.3, 13.4, 14.6, 15.8, 17.0, 18.2]","title":"GaborEffectiveWidth"},{"location":"indeep/#gaborwavelength","text":"Default values: [3.5, 4.6, 5.6, 6.8, 7.9, 9.1, 10.3, 11.5, 12.7, 14.1, 15.4, 16.8, 18.2, 19.7, 21.2, 22.8]","title":"GaborWavelength"},{"location":"indeep/#gaborfiltersizes","text":"Default values: [7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37]","title":"GaborFilterSizes"},{"location":"indeep/#maxpoolingsizes","text":"Default values: [8, 8, 10, 10, 12, 12, 14, 14, 16, 16, 18, 18, 20, 20, 22, 22]","title":"MaxPoolingSizes"},{"location":"installation/","text":"Installation HMAX is written in Matlab . Matlab is a proprietary software; thus you must have a Matlab licence. In addition, you will need the following Toolboxes to run this version of HMAX: Requirement Matlab 2017 Optimization toolbox Parallel Computing Toolbox (optional) Global Optimization Toolbox (for sparse coding only) Statistics and Machine Learning Toolbox ( for image classification only) Then download the code through git: git clone https://github.com/EEVCOM-Montpellier/HMAX Or download it directly at: https://github.com/EEVCOM-Montpellier/HMAX/archive/master.zip","title":"Installation"},{"location":"installation/#installation","text":"HMAX is written in Matlab . Matlab is a proprietary software; thus you must have a Matlab licence. In addition, you will need the following Toolboxes to run this version of HMAX: Requirement Matlab 2017 Optimization toolbox Parallel Computing Toolbox (optional) Global Optimization Toolbox (for sparse coding only) Statistics and Machine Learning Toolbox ( for image classification only) Then download the code through git: git clone https://github.com/EEVCOM-Montpellier/HMAX Or download it directly at: https://github.com/EEVCOM-Montpellier/HMAX/archive/master.zip","title":"Installation"},{"location":"methodology-and-results/","text":"Performance test with Caltech101 We compared our version of HMAX (Renoult et al. 2019) to that provided by Thomas Serre's Lab, available here: https://github.com/serre-lab/color_hmax Comparisons were made on a classification task using the Caltech101 dataset, available here . This dataset contains 102 categories, which include between 31 and more than 800 images. Analyses were performed with the 102 categories, and with a reduced database of only 20 categories. The Caltech20 dataset contained the following categories: Airplanes Electric guitar Hedgehog Minaret Binocular Emu Joshua tree Pigeon Chandelier Faces Laptop Rooster Dolphin Gerenuk Mandolin Sea horse Strawberry Trilobite Water lilly Windsor chair Images were resized to 140 pix for the smallest side, keeping the aspect ratio unchanged. We used 15 images per category to first learn the set of S2 filters, extracting 1,000 filters from C1 with HMAX and 4,000 filters with colour HMAX (1,000 for each DO channel), and learning 250 filters with sparse-HMAX (both greyscale and colour versions). Note that, in order to compare our results to those of previous studies, we used a red-cyan opponent channel in addition to the yellow-blue, red-green and achromatic channels (Zhang et al., 2012). For the classification task, we randomly selected 31 pictures from each of the 102 categories and encoded them with the previously learned HMAX models. Among these 31 pictures, 25 were used for training the classifier and six for testing. The multiclass classifier consisted of 102 binary linear Support Vector Machines (one per category). During training, we applied a cross-validation procedure with five clusters to limit over-fitting. Results - Caltech 20 Renoult et al. Serre et al. Renoult et al. Serre et al. Renoult et al. Engine Classic Gray Color Color DO Sparse coding Correct classification rate 57.14% 58.57% 64.29% 50.71% 45.71% Execution time 57m25s 1h16m16s 13h28m22s 11h09m34s 2h48m00s Results - Caltech 101 Renoult et al. Serre et al. Renoult et al. Serre et al. Renoult et al. Engine Classic Gray Color Color DO Sparse coding Correct classification rate 31.79% 27.45% 29.55% 25.63% --.--% Execution time 4h38m33s 6h4m8s 2d21h22m2s 2d4h11m30s -h--m--s","title":"Methodology and results"},{"location":"methodology-and-results/#performance-test-with-caltech101","text":"We compared our version of HMAX (Renoult et al. 2019) to that provided by Thomas Serre's Lab, available here: https://github.com/serre-lab/color_hmax Comparisons were made on a classification task using the Caltech101 dataset, available here . This dataset contains 102 categories, which include between 31 and more than 800 images. Analyses were performed with the 102 categories, and with a reduced database of only 20 categories. The Caltech20 dataset contained the following categories: Airplanes Electric guitar Hedgehog Minaret Binocular Emu Joshua tree Pigeon Chandelier Faces Laptop Rooster Dolphin Gerenuk Mandolin Sea horse Strawberry Trilobite Water lilly Windsor chair Images were resized to 140 pix for the smallest side, keeping the aspect ratio unchanged. We used 15 images per category to first learn the set of S2 filters, extracting 1,000 filters from C1 with HMAX and 4,000 filters with colour HMAX (1,000 for each DO channel), and learning 250 filters with sparse-HMAX (both greyscale and colour versions). Note that, in order to compare our results to those of previous studies, we used a red-cyan opponent channel in addition to the yellow-blue, red-green and achromatic channels (Zhang et al., 2012). For the classification task, we randomly selected 31 pictures from each of the 102 categories and encoded them with the previously learned HMAX models. Among these 31 pictures, 25 were used for training the classifier and six for testing. The multiclass classifier consisted of 102 binary linear Support Vector Machines (one per category). During training, we applied a cross-validation procedure with five clusters to limit over-fitting.","title":"Performance test with Caltech101"},{"location":"methodology-and-results/#results-caltech-20","text":"Renoult et al. Serre et al. Renoult et al. Serre et al. Renoult et al. Engine Classic Gray Color Color DO Sparse coding Correct classification rate 57.14% 58.57% 64.29% 50.71% 45.71% Execution time 57m25s 1h16m16s 13h28m22s 11h09m34s 2h48m00s","title":"Results - Caltech 20"},{"location":"methodology-and-results/#results-caltech-101","text":"Renoult et al. Serre et al. Renoult et al. Serre et al. Renoult et al. Engine Classic Gray Color Color DO Sparse coding Correct classification rate 31.79% 27.45% 29.55% 25.63% --.--% Execution time 4h38m33s 6h4m8s 2d21h22m2s 2d4h11m30s -h--m--s","title":"Results - Caltech 101"},{"location":"visualization/","text":"Visualization For visualize the different activations cards, you can use functions available in the helpers.display package.","title":"Visualization"},{"location":"visualization/#visualization","text":"For visualize the different activations cards, you can use functions available in the helpers.display package.","title":"Visualization"}]}
{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"HMAX documentation Welcome to the HMAX documentation (version Renoult et al. 2019). For instructions about how to install the MATLAB package, go here . If you have already downloaded the package, go here to start using it. What is HMAX? HMAX is a computational model of information processing in the ventral pathway of the visal cortex, which is involved in colour and shape perception. The model was proposed originally by Riesenhuber Poggio (1999). What is new in this version? This version of HMAX offers high flexibility in parameter setting and thus can be easily tuned to model the perception of colour patterns in a wide array of Vertebrate species. This package also includes sparse-HMAX, an extension of HMAX with a sparse coding scheme, as an attempts to make the model even more biologically realistic and to provide a tool for estimating efficiency in information processing. As in the version proposed by Zhang et al. (2012), it can process greyscale or colour images; however, it is up to 25% faster. Renoult et al. (2019) provides a complete description of the model. References Mutch, J., Lowe, D. G. (2006). Multiclass object recognition with sparse, localized features. In Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on (Vol. 1, pp. 11-18). IEEE. Renoult, J.P., Guyl, B., Mendelson, T.C., et al. (2019). Modelling the Perception of Colour Patterns in Vertebrates with HMAX. preprint here. Riesenhuber, M., Poggio, T. (1999). Hierarchical models of object recognition in cortex. Nature neuroscience, 2(11), 1019. Serre, T., Wolf, L., Bileschi, S., Riesenhuber, M., Poggio, T. (2007). Robust object recognition with cortex-like mechanisms. IEEE Transactions on Pattern Analysis Machine Intelligence, (3), 411-426. Zhang, J., Barhomi, Y., Serre, T. (2012, October). A new biologically inspired color image descriptor. In European Conference on Computer Vision (pp. 312-324). Springer, Berlin, Heidelberg. Links Riesenhuber (original HMAX) http://maxlab.neuro.georgetown.edu/hmax Serre (codes for HMAX and colour HMAX) https://github.com/serre-lab/color_hmax Mutch (yet another implement of HMAX) http://cbcl.mit.edu/jmutch/cns About us You can find more on our EEVCOM webpage.","title":"Home"},{"location":"#hmax-documentation","text":"Welcome to the HMAX documentation (version Renoult et al. 2019). For instructions about how to install the MATLAB package, go here . If you have already downloaded the package, go here to start using it.","title":"HMAX documentation"},{"location":"#what-is-hmax","text":"HMAX is a computational model of information processing in the ventral pathway of the visal cortex, which is involved in colour and shape perception. The model was proposed originally by Riesenhuber Poggio (1999).","title":"What is HMAX?"},{"location":"#what-is-new-in-this-version","text":"This version of HMAX offers high flexibility in parameter setting and thus can be easily tuned to model the perception of colour patterns in a wide array of Vertebrate species. This package also includes sparse-HMAX, an extension of HMAX with a sparse coding scheme, as an attempts to make the model even more biologically realistic and to provide a tool for estimating efficiency in information processing. As in the version proposed by Zhang et al. (2012), it can process greyscale or colour images; however, it is up to 25% faster. Renoult et al. (2019) provides a complete description of the model.","title":"What is new in this version?"},{"location":"#references","text":"Mutch, J., Lowe, D. G. (2006). Multiclass object recognition with sparse, localized features. In Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on (Vol. 1, pp. 11-18). IEEE. Renoult, J.P., Guyl, B., Mendelson, T.C., et al. (2019). Modelling the Perception of Colour Patterns in Vertebrates with HMAX. preprint here. Riesenhuber, M., Poggio, T. (1999). Hierarchical models of object recognition in cortex. Nature neuroscience, 2(11), 1019. Serre, T., Wolf, L., Bileschi, S., Riesenhuber, M., Poggio, T. (2007). Robust object recognition with cortex-like mechanisms. IEEE Transactions on Pattern Analysis Machine Intelligence, (3), 411-426. Zhang, J., Barhomi, Y., Serre, T. (2012, October). A new biologically inspired color image descriptor. In European Conference on Computer Vision (pp. 312-324). Springer, Berlin, Heidelberg.","title":"References"},{"location":"#links","text":"","title":"Links"},{"location":"#riesenhuber-original-hmax","text":"http://maxlab.neuro.georgetown.edu/hmax","title":"Riesenhuber (original HMAX)"},{"location":"#serre-codes-for-hmax-and-colour-hmax","text":"https://github.com/serre-lab/color_hmax","title":"Serre (codes for HMAX and colour HMAX)"},{"location":"#mutch-yet-another-implement-of-hmax","text":"http://cbcl.mit.edu/jmutch/cns","title":"Mutch (yet another implement of HMAX)"},{"location":"#about-us","text":"You can find more on our EEVCOM webpage.","title":"About us"},{"location":"custom-parameters/","text":"Custom parameters In this section, we will show how to use parameters settings in HMAX. If you haven't read it yet, you should start with the Get started section. How to specify parameters There is two ways to set parameters in the program: Directly through the Matlab command From a configuration file The priority is given to: 1. Parameters set through the Matlab command 2. Parameters written in the configuration file 3. Parameters set internally So if we write: hmax('../dataset/train/', 'Train', true); The Train parameter is set to false internally and in the default configuration file. Setting the parameter to true will override the default value. So the HLFilter dictionnary will be rebuild. Avalaible parameters Name Description Type expected Default value ConfigurationFile Custom configuration file String - JSON file \"./defaultParameters.json\" Output Custom output directory String - Directory \"./results\" GPU Use GPU for computation Boolean false Parallel Use parallel computing Boolean false Engine Specify an algorithm to use String \"sparseCodingColor\" ImageSize Resize image to this size in pixels Integer 140 GaborNbOrientations Nb. of oritentions for Gabor filters Integer 4 GaborAspectRatio Spatial aspect ratio of Gabor filters Float 0.3 GaborEffectiveWidth Width of Gabor filters Float[] [2.8, 3.6, 4.5, ..., 18.2] GaborWavelength Wavelength of Gabor filters Float[] [3.5, 4.6, 5.6, ..., 22.8] GaborSizes Sizes of Gabor filters Integer[] [7, 9, 11, 13, ..., 39] FiltersSizes Sizes of S2 filters Integer[] [4, 8, 12, 16] MaxPoolingSizes Size of the max pooling Integer[] [8, 8, 10, 10, ..., 22] ColorNbChannels Nb. of color channels Integer 4 SparseCodingFilterSize Sizes of S2 filters (sparse HMAX) Integer 12 SparseCodingNbPatches Nb. of patches extracted (sparse HMAX) Integer 10000 SparseCodingBatchSize Nb. of patches in one batch during filter learning (sparse HMAX) Integer 1000 SparseCodingNbIterations Nb. of iterations during filter learning (sparse HMAX) Integer 2 SparseCodingPenalty Importance given to sparseness versus reconstruction error (sparse HMAX) Float 0.2 NbFilters Nb. of S2 fitlers (sparse HMAX) Integer 1000 Train Train the model Boolean false Save Save all the layers or just the last one String C2 HlFiltersLocation Location of the dictonnary of HLFilters String - Filepath ./data/classic_hlfilters.mat Engine Choose between: classic (HMAX with greyscale images), sparseCoding (HMAX with sparse coding), color (HMAX with colour images) or sparseColor (HMAX with sparse coding on colour images) ImageSize Input images are resized to have their smallest side equal to the defined value keeping aspect ration constant. Large images increase computation time. GaborEffectiveWidth Default values: [2.8, 3.6, 4.5, 5.4, 6.3, 7.3, 8.2, 9.2, 10.2, 11.3, 12.3, 13.4, 14.6, 15.8, 17.0, 18.2] GaborWavelength Default values: [3.5, 4.6, 5.6, 6.8, 7.9, 9.1, 10.3, 11.5, 12.7, 14.1, 15.4, 16.8, 18.2, 19.7, 21.2, 22.8] GaborFilterSizes Default values: [7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37] MaxPoolingSizes Default values: [8, 8, 10, 10, 12, 12, 14, 14, 16, 16, 18, 18, 20, 20, 22, 22] Save Choose beween: all or C2 . Becareful, choosing to save all the layers will result in large .mat files. HlFiltersLocation If Train=true , the dictonnary will be saved at the specified location. Else, the programm will try to load the given file.","title":"Custom parameters"},{"location":"custom-parameters/#custom-parameters","text":"In this section, we will show how to use parameters settings in HMAX. If you haven't read it yet, you should start with the Get started section.","title":"Custom parameters"},{"location":"custom-parameters/#how-to-specify-parameters","text":"There is two ways to set parameters in the program: Directly through the Matlab command From a configuration file The priority is given to: 1. Parameters set through the Matlab command 2. Parameters written in the configuration file 3. Parameters set internally So if we write: hmax('../dataset/train/', 'Train', true); The Train parameter is set to false internally and in the default configuration file. Setting the parameter to true will override the default value. So the HLFilter dictionnary will be rebuild.","title":"How to specify parameters"},{"location":"custom-parameters/#avalaible-parameters","text":"Name Description Type expected Default value ConfigurationFile Custom configuration file String - JSON file \"./defaultParameters.json\" Output Custom output directory String - Directory \"./results\" GPU Use GPU for computation Boolean false Parallel Use parallel computing Boolean false Engine Specify an algorithm to use String \"sparseCodingColor\" ImageSize Resize image to this size in pixels Integer 140 GaborNbOrientations Nb. of oritentions for Gabor filters Integer 4 GaborAspectRatio Spatial aspect ratio of Gabor filters Float 0.3 GaborEffectiveWidth Width of Gabor filters Float[] [2.8, 3.6, 4.5, ..., 18.2] GaborWavelength Wavelength of Gabor filters Float[] [3.5, 4.6, 5.6, ..., 22.8] GaborSizes Sizes of Gabor filters Integer[] [7, 9, 11, 13, ..., 39] FiltersSizes Sizes of S2 filters Integer[] [4, 8, 12, 16] MaxPoolingSizes Size of the max pooling Integer[] [8, 8, 10, 10, ..., 22] ColorNbChannels Nb. of color channels Integer 4 SparseCodingFilterSize Sizes of S2 filters (sparse HMAX) Integer 12 SparseCodingNbPatches Nb. of patches extracted (sparse HMAX) Integer 10000 SparseCodingBatchSize Nb. of patches in one batch during filter learning (sparse HMAX) Integer 1000 SparseCodingNbIterations Nb. of iterations during filter learning (sparse HMAX) Integer 2 SparseCodingPenalty Importance given to sparseness versus reconstruction error (sparse HMAX) Float 0.2 NbFilters Nb. of S2 fitlers (sparse HMAX) Integer 1000 Train Train the model Boolean false Save Save all the layers or just the last one String C2 HlFiltersLocation Location of the dictonnary of HLFilters String - Filepath ./data/classic_hlfilters.mat","title":"Avalaible parameters"},{"location":"custom-parameters/#engine","text":"Choose between: classic (HMAX with greyscale images), sparseCoding (HMAX with sparse coding), color (HMAX with colour images) or sparseColor (HMAX with sparse coding on colour images)","title":"Engine"},{"location":"custom-parameters/#imagesize","text":"Input images are resized to have their smallest side equal to the defined value keeping aspect ration constant. Large images increase computation time.","title":"ImageSize"},{"location":"custom-parameters/#gaboreffectivewidth","text":"Default values: [2.8, 3.6, 4.5, 5.4, 6.3, 7.3, 8.2, 9.2, 10.2, 11.3, 12.3, 13.4, 14.6, 15.8, 17.0, 18.2]","title":"GaborEffectiveWidth"},{"location":"custom-parameters/#gaborwavelength","text":"Default values: [3.5, 4.6, 5.6, 6.8, 7.9, 9.1, 10.3, 11.5, 12.7, 14.1, 15.4, 16.8, 18.2, 19.7, 21.2, 22.8]","title":"GaborWavelength"},{"location":"custom-parameters/#gaborfiltersizes","text":"Default values: [7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37]","title":"GaborFilterSizes"},{"location":"custom-parameters/#maxpoolingsizes","text":"Default values: [8, 8, 10, 10, 12, 12, 14, 14, 16, 16, 18, 18, 20, 20, 22, 22]","title":"MaxPoolingSizes"},{"location":"custom-parameters/#save","text":"Choose beween: all or C2 . Becareful, choosing to save all the layers will result in large .mat files.","title":"Save"},{"location":"custom-parameters/#hlfilterslocation","text":"If Train=true , the dictonnary will be saved at the specified location. Else, the programm will try to load the given file.","title":"HlFiltersLocation"},{"location":"get-started/","text":"Get started This section will show you how to process images with the HMAX algorithm. Quick start HMAX needs a dictionnary of high level filters (later HLFilters) in order to work. Renoult and al. HMAX come with pre-build dictionnaries, so that you will easely process your images. Theses steps bellow run Renoult HMAX with the default configuration and dictionnany: Open the project with Matlab. Run the code on your images hmax('path/to/your/images'); This will read recursively the path/to/your/images folder architecture and create a similar one in the ./result folder. Each images will give a Matlab binary file containing the HMAX encoding. Troubleshouting The code doesn't run because I don't have the Parallelization package You can still run it by specifiyng that you don't want to use parallelization: hmax('path/to/your/images', 'Parallel', false); What's next? Learn a custom HLFilter dictonnary: Learn dictionnaries Learn how to use custom parameters: Custom parameters Use Machine Learning tools: Machine Learning","title":"Get started"},{"location":"get-started/#get-started","text":"This section will show you how to process images with the HMAX algorithm.","title":"Get started"},{"location":"get-started/#quick-start","text":"HMAX needs a dictionnary of high level filters (later HLFilters) in order to work. Renoult and al. HMAX come with pre-build dictionnaries, so that you will easely process your images. Theses steps bellow run Renoult HMAX with the default configuration and dictionnany: Open the project with Matlab. Run the code on your images hmax('path/to/your/images'); This will read recursively the path/to/your/images folder architecture and create a similar one in the ./result folder. Each images will give a Matlab binary file containing the HMAX encoding.","title":"Quick start"},{"location":"get-started/#troubleshouting","text":"The code doesn't run because I don't have the Parallelization package You can still run it by specifiyng that you don't want to use parallelization: hmax('path/to/your/images', 'Parallel', false);","title":"Troubleshouting"},{"location":"get-started/#whats-next","text":"Learn a custom HLFilter dictonnary: Learn dictionnaries Learn how to use custom parameters: Custom parameters Use Machine Learning tools: Machine Learning","title":"What's next?"},{"location":"installation/","text":"Installation HMAX is written in Matlab . Matlab is a proprietary software; thus you must have a Matlab licence. In addition, you will need the following Toolboxes to run this version of HMAX: Requirement Matlab 2017 Optimization toolbox Parallel Computing Toolbox (optional) Global Optimization Toolbox (for sparse coding only) Statistics and Machine Learning Toolbox ( for image classification only) Then download the code through git: git clone https://github.com/EEVCOM-Montpellier/HMAX Or download it directly at: https://github.com/EEVCOM-Montpellier/HMAX/archive/master.zip","title":"Installation"},{"location":"installation/#installation","text":"HMAX is written in Matlab . Matlab is a proprietary software; thus you must have a Matlab licence. In addition, you will need the following Toolboxes to run this version of HMAX: Requirement Matlab 2017 Optimization toolbox Parallel Computing Toolbox (optional) Global Optimization Toolbox (for sparse coding only) Statistics and Machine Learning Toolbox ( for image classification only) Then download the code through git: git clone https://github.com/EEVCOM-Montpellier/HMAX Or download it directly at: https://github.com/EEVCOM-Montpellier/HMAX/archive/master.zip","title":"Installation"},{"location":"learn-dictionnaries/","text":"Learn dictionnaries To learn a new dictionnary, you must: Turn the train option to true Specify a file name, with .mat extension, where to save the dictionnary Give the train dataset Exemple hmax('your/train/dataset', 'Train', true, 'HLFiltersLocation', './data/my-custom-dictionnary.mat') You must use the same Engine in the training and the execution session. I.e., if you learn a sparseCoding dictionnary, you must execute a sparseCoding encoding, you can't use this dictionnary with classic , color or even sparseColor .","title":"Learn dictionnaries"},{"location":"learn-dictionnaries/#learn-dictionnaries","text":"To learn a new dictionnary, you must: Turn the train option to true Specify a file name, with .mat extension, where to save the dictionnary Give the train dataset Exemple hmax('your/train/dataset', 'Train', true, 'HLFiltersLocation', './data/my-custom-dictionnary.mat') You must use the same Engine in the training and the execution session. I.e., if you learn a sparseCoding dictionnary, you must execute a sparseCoding encoding, you can't use this dictionnary with classic , color or even sparseColor .","title":"Learn dictionnaries"},{"location":"machine-learning/","text":"Machine Learning The code come with some tools to use machine learning models. Here, we will describe how to use them. Prepare your dataset First, you must prepare your dataset. The simplest way is to have one folder per label containing your images. You encode you dataset and then split it for machine learning purposes. Encode your images hmax('../dataset'); This will read recursively the ../dataset/ folder architecture and create a similar one in the ./result folder. Each images will give a Matlab binary file containing the HMAX encoding. If your folders are named corresponding to the label of the images, then you can run the following command: T = classifier.loadC2s('./results/'); Where T is a table containing HMAX encodings with corresponding labels. Now you can use the data directly in a Machine Learning tool. The recommendation is to split the data ( T ) in two, one with 80% of the observations for training and the other with the rest of the 20% for validation. [Ttrain Ttest] = classifier.splitdata(T, 0.8); Then, you can use the Classification Learner toolbox to create a model. For our tests, we used a Linear SVM without PCA. Finally, we can test our model averagePrecision = classifier.runtest(trainedModel, Ttest) Go further Now that you know how to run HMAX, we will see how to run the code with GPU, parallel computing, with your own parameters, etc ...","title":"Machine Learning"},{"location":"machine-learning/#machine-learning","text":"The code come with some tools to use machine learning models. Here, we will describe how to use them.","title":"Machine Learning"},{"location":"machine-learning/#prepare-your-dataset","text":"First, you must prepare your dataset. The simplest way is to have one folder per label containing your images. You encode you dataset and then split it for machine learning purposes. Encode your images hmax('../dataset'); This will read recursively the ../dataset/ folder architecture and create a similar one in the ./result folder. Each images will give a Matlab binary file containing the HMAX encoding. If your folders are named corresponding to the label of the images, then you can run the following command: T = classifier.loadC2s('./results/'); Where T is a table containing HMAX encodings with corresponding labels. Now you can use the data directly in a Machine Learning tool. The recommendation is to split the data ( T ) in two, one with 80% of the observations for training and the other with the rest of the 20% for validation. [Ttrain Ttest] = classifier.splitdata(T, 0.8); Then, you can use the Classification Learner toolbox to create a model. For our tests, we used a Linear SVM without PCA. Finally, we can test our model averagePrecision = classifier.runtest(trainedModel, Ttest)","title":"Prepare your dataset"},{"location":"machine-learning/#go-further","text":"Now that you know how to run HMAX, we will see how to run the code with GPU, parallel computing, with your own parameters, etc ...","title":"Go further"},{"location":"methodology-and-results/","text":"Performance test with Caltech101 We compared our version of HMAX (Renoult et al. 2019) to that provided by Thomas Serre's Lab, available here: https://github.com/serre-lab/color_hmax Comparisons were made on a classification task using the Caltech101 dataset, available here . This dataset contains 102 categories, which include between 31 and more than 800 images. Analyses were performed with the 102 categories, and with a reduced database of only 20 categories. The Caltech20 dataset contained the following categories: Airplanes Electric guitar Hedgehog Minaret Binocular Emu Joshua tree Pigeon Chandelier Faces Laptop Rooster Dolphin Gerenuk Mandolin Sea horse Strawberry Trilobite Water lilly Windsor chair Images were resized to 140 pix for the smallest side, keeping the aspect ratio unchanged. We used 15 images per category to first learn the set of S2 filters, extracting 1,000 filters from C1 with HMAX and 4,000 filters with colour HMAX (1,000 for each DO channel), and learning 250 filters with sparse-HMAX (both greyscale and colour versions). We used a red-cyan opponent channel in addition to the yellow-blue, red-green and achromatic channels (Zhang et al., 2012). For the classification task, we randomly selected 31 pictures from each of the 102 categories and encoded them with the previously learned HMAX models. Among these 31 pictures, 25 were used for training the classifier and six for testing. The multiclass classifier consisted of 102 binary linear Support Vector Machines (one per category). During training, we applied a cross-validation procedure with five clusters to limit over-fitting. Results - Caltech 20 Renoult et al. Serre et al. Renoult et al. Serre et al. Renoult et al. Renoult et al. Engine Classic Gray Color Color DO Sparse coding Sparse coding color Correct classification 57.14% 58.57% 64.29% 50.71% 45.71% 53.57% Execution time 57m25s 1h16m16s 13h28m22s 11h09m34s 2h48m00s 9h23m42s Results - Caltech 101 Renoult et al. Serre et al. Renoult et al. Serre et al. Renoult et al. Renoult et al. Engine Classic Gray Color Color DO Sparse coding Sparse coding color Correct classification 31.79% 27.45% 29.55% 25.63% 18.77% 23.11% Execution time 4h38m33s 6h4m8s 2d21h22m2s 2d4h11m30s 4h52m30 20h53m43","title":"Methodology and results"},{"location":"methodology-and-results/#performance-test-with-caltech101","text":"We compared our version of HMAX (Renoult et al. 2019) to that provided by Thomas Serre's Lab, available here: https://github.com/serre-lab/color_hmax Comparisons were made on a classification task using the Caltech101 dataset, available here . This dataset contains 102 categories, which include between 31 and more than 800 images. Analyses were performed with the 102 categories, and with a reduced database of only 20 categories. The Caltech20 dataset contained the following categories: Airplanes Electric guitar Hedgehog Minaret Binocular Emu Joshua tree Pigeon Chandelier Faces Laptop Rooster Dolphin Gerenuk Mandolin Sea horse Strawberry Trilobite Water lilly Windsor chair Images were resized to 140 pix for the smallest side, keeping the aspect ratio unchanged. We used 15 images per category to first learn the set of S2 filters, extracting 1,000 filters from C1 with HMAX and 4,000 filters with colour HMAX (1,000 for each DO channel), and learning 250 filters with sparse-HMAX (both greyscale and colour versions). We used a red-cyan opponent channel in addition to the yellow-blue, red-green and achromatic channels (Zhang et al., 2012). For the classification task, we randomly selected 31 pictures from each of the 102 categories and encoded them with the previously learned HMAX models. Among these 31 pictures, 25 were used for training the classifier and six for testing. The multiclass classifier consisted of 102 binary linear Support Vector Machines (one per category). During training, we applied a cross-validation procedure with five clusters to limit over-fitting.","title":"Performance test with Caltech101"},{"location":"methodology-and-results/#results-caltech-20","text":"Renoult et al. Serre et al. Renoult et al. Serre et al. Renoult et al. Renoult et al. Engine Classic Gray Color Color DO Sparse coding Sparse coding color Correct classification 57.14% 58.57% 64.29% 50.71% 45.71% 53.57% Execution time 57m25s 1h16m16s 13h28m22s 11h09m34s 2h48m00s 9h23m42s","title":"Results - Caltech 20"},{"location":"methodology-and-results/#results-caltech-101","text":"Renoult et al. Serre et al. Renoult et al. Serre et al. Renoult et al. Renoult et al. Engine Classic Gray Color Color DO Sparse coding Sparse coding color Correct classification 31.79% 27.45% 29.55% 25.63% 18.77% 23.11% Execution time 4h38m33s 6h4m8s 2d21h22m2s 2d4h11m30s 4h52m30 20h53m43","title":"Results - Caltech 101"},{"location":"visualization/","text":"Visualization To visualize the different activations maps, use functions available in the helpers.display package. Display S1 and C1 In order to visualize S1 ans C1, you can use the display.P1 function. (P1 stand for Phase 1). fig = display.P1(S1); This result in this type of figure: Here, we have our image filtered by a gabor filter in 4 orientations and in 16 scale. The same thing after the max pooling:","title":"Visualization"},{"location":"visualization/#visualization","text":"To visualize the different activations maps, use functions available in the helpers.display package.","title":"Visualization"},{"location":"visualization/#display-s1-and-c1","text":"In order to visualize S1 ans C1, you can use the display.P1 function. (P1 stand for Phase 1). fig = display.P1(S1); This result in this type of figure: Here, we have our image filtered by a gabor filter in 4 orientations and in 16 scale. The same thing after the max pooling:","title":"Display S1 and C1"}]}